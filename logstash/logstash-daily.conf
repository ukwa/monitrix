input {
  file {
    path => "/heritrix/output/logs/daily/*/crawl.log"
    exclude => "*crawl.log.cp*"
#    start_position => beginning
  }
}
filter {
  grok {
    match => [ "message", "%{NOTSPACE:log_timestamp} +%{NUMBER:fetch_status_code:int} +%{NOTSPACE:resource_size:int} %{NOTSPACE:downloaded_uri} %{NOTSPACE:discovery_path} %{NOTSPACE:referrer_uri} %{NOTSPACE:mime_type} %{NOTSPACE:worker_thread_id} %{NOTSPACE:fetch_timestamp} %{NOTSPACE:sha1_digest} %{NOTSPACE:source_tag} %{NOTSPACE:annotations}" ]
    add_field => { 
      "crawl_id" => "daily"
    }
  }
  date {
    match => [ "log_timestamp", "ISO8601" ]
  }
  mutate {
    split => [ "annotations", "," ]
  }
  if [downloaded_uri] =~ /^http.*/ {
    grok {
      match => [ "downloaded_uri", "%{WORD:downloaded_uri_scheme}://%{HOSTNAME:downloaded_uri_host}(?:%{NOTSPACE:downloaded_uri_path_and_query}|)" ]
    }
  } else if [downloaded_uri] != "-" {
    grok {
      match => [ "downloaded_uri", "%{WORD:downloaded_uri_scheme}:%{NOTSPACE:downloaded_uri_host}" ]
    }
  }
  if [fetch_timestamp] != "-" {
    grok {
      match => [ "fetch_timestamp", "%{POSINT:fetch_start}\+%{POSINT:fetch_duration:int}" ]
    }
  }
}
output {
  elasticsearch_http { 
    host => "192.168.45.250"
    index => "logstash-h3-crawl-log-%{+YYYY.MM}"
  }
#  stdout { codec => rubydebug }
}
